{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fefb206",
   "metadata": {},
   "source": [
    "# Lab 8 - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c74f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'audio'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/audio.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0bedf7",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e661ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6488b5",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3e82b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 7],\n",
      "        [8, 9]])\n",
      "tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "tensor_add = tensor + 5\n",
    "print(tensor_add)\n",
    "\n",
    "# Multiplication\n",
    "tensor_mul = tensor * 2\n",
    "print(tensor_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5396c",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce12641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with requires_grad=True to track computation\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "# Compute gradients\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b913b11",
   "metadata": {},
   "source": [
    "In backpropagation, gradients show how much a small change in each parameter affects the overall error of the model. They help adjust the parameters to minimize this error. Think of gradients like a compass pointing towards the direction of improvement. During training, we calculate these gradients and use them to update the parameters, making the model better at its task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a49cf2",
   "metadata": {},
   "source": [
    "### Building a Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43899c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear model\n",
    "model = torch.nn.Linear(1, 1)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e8dcc",
   "metadata": {},
   "source": [
    "The inputs provided in torch.nn.Linear are:\n",
    "\n",
    "    Input Features (in_features): This parameter specifies the size of each input sample. In the context of a linear layer, it represents the number of input features or dimensions. For example, if each input sample has 3 features, then in_features=3.\n",
    "\n",
    "    Output Features (out_features): This parameter specifies the size of the output tensor. It represents the number of output features or dimensions. For example, if we want the linear layer to produce output with 2 features, then out_features=2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f253ed6",
   "metadata": {},
   "source": [
    "## Implement a Multi-Layer Neural Network with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e83718",
   "metadata": {},
   "source": [
    "### Task 1: Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4132468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Generating a spiral dataset\n",
    "N = 100  # number of points per class\n",
    "D = 2  # dimensionality\n",
    "K = 2  # number of classes\n",
    "X = np.zeros((N*K, D))  # data matrix (each row = single example)\n",
    "y = np.zeros(N*K, dtype='uint8')  # class labels\n",
    "\n",
    "for j in range(K):\n",
    "  ix = range(N*j, N*(j+1))\n",
    "  r = np.linspace(0.0, 1, N)  # radius\n",
    "  t = np.linspace(j*4, (j+1)*4, N) + np.random.randn(N)*0.2  # theta\n",
    "  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "  y[ix] = j\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951b79b",
   "metadata": {},
   "source": [
    "### Task 2: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343fc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple multi-layer network\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 100),  # 2 inputs, to 100 neurons in the first hidden layer\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 50),  # Second hidden layer, 50 neurons\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 2)  # Output layer, 2 outputs for our classes\n",
    ")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea514f",
   "metadata": {},
   "source": [
    "### Task 3: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4cf482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.6883038282394409\n",
      "Epoch 100: loss = 0.013742297887802124\n",
      "Epoch 200: loss = 0.009808138012886047\n",
      "Epoch 300: loss = 0.008119741454720497\n",
      "Epoch 400: loss = 0.007577527780085802\n",
      "Epoch 500: loss = 0.007354358211159706\n",
      "Epoch 600: loss = 0.007192573510110378\n",
      "Epoch 700: loss = 0.007121950387954712\n",
      "Epoch 800: loss = 0.007230255752801895\n",
      "Epoch 900: loss = 0.0071966201066970825\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Zero gradients, backward pass, and update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}: loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4c664",
   "metadata": {},
   "source": [
    "### Task 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use matplotlib to plot the decision boundary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_boundary(pred_func):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    \n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predict the function value for the whole grid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, edgecolor='k')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "# Model prediction for a numpy array\n",
    "def predict(X):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    y_pred = model(X)\n",
    "    return np.argmax(y_pred.data.numpy(), axis=1)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: predict(x))\n",
    "plt.title(\"Decision Boundary\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
